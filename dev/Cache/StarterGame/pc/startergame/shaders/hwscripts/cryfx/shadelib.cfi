////////////////////////////////////////////////////////////////////////////
//
//  Crytek Engine Source File.
//  Shader extension
//  Copyright (C), Crytek Studios, 2001-2004.
// -------------------------------------------------------------------------
//  File name:   ShadeLib.cfi
//  Version:     v1.00
//  Created:     19/05/2006 by Tiago Sousa
//  Compilers:   
//  Description: Common BRDF's/shading utilities library
//
// -------------------------------------------------------------------------
////////////////////////////////////////////////////////////////////////////

// Common Samplers //////////////////////

DIFFUSEMAP
NORMALMAP
HEIGHTMAP
SPECULARMAP
SMOOTHNESSMAP
SCENEDEPTHMAP

sampler2D diffuseMapSampler_Decal
{ 
	Texture = $Diffuse; 	
	AddressU = Border;
	AddressV = Border;
	BorderColor = {0, 0, 0, 0};	
  sRGBLookup = true; 
};

sampler2D detailMapSampler = sampler_state
{
  Texture = $Detail;
};

// Deferred Shading Samplers /////////////

SCENE_NORMALS_MAP
SCENE_NORMALS_BENT
SCENE_DIFFUSEACC_MAP
SCENE_SPECULARACC_MAP

////////////////////////////////////////////////////////////////////////////////////////////////////

#define REFLECT_OFF    0
#define REFLECT_CUBE   1
#define REFLECT_SPHERE 2

////////////////////////////////////////////////////////////////////////////////////////////////////

float4 miscCamFront : PB_CameraFront;

// Shared fragment-shading pass structure ////////////////////////////

struct fragInput
{
  // input attribute data
  float4 baseTC;
#if %BLENDLAYER
  // Un-modulated texture coordinates used by blend map and modulated blend layer texture coordinates used by 2nd diffuse, 2nd height, etc.
  float4 blendMapTCblendLayerTC;
#endif
#if %EMITTANCE_MAP
  float2 emittanceTC;
  float2 emissiveIntensityTC;
#endif
#if %DETAIL_MAPPING
  float2 detailTC;
#endif
  float4 basesectorTC;
  float4 bumpTC;
  float4 terrainDetailTC;
  
  half4 vTangent;
  half4 vBinormal;
  half4 vNormal;
  half4 vView;
  
  float4 screenProj;
  float4 projTC;
  
  half4 Color;
  half4 Color1;
  float4 VisTerrainCol;
  float4 SunRefl;
  half4 Ambient;

  half4 AlphaTest;
  
  float3 DistAtten;
  float4 AvgFogVolumeContrib;
  
  float4 OutdoorAOInfo;

	uint uSample;
};

struct fragPass
{
    fragInput IN;

    // Usage flags fo shared stuff  
    bool bCustomComposition;      // dont use shared final shading composition
    bool bRenormalizeNormal;
    bool bDontUseBump;
    bool bDetailBumpMapping;
    bool bDetailBumpMappingMasking;
    bool bVertexColors;      // apply vertex color to final result
    bool bApplyGI; 
    bool bDeferredSpecularShading;
    bool bSkipDirectLighting;
    int  nReflectionMapping; // reflection mapping type (0: off, 1: cube map, 2: spherical)

    int  nMicroDetailQuality;
    half fBumpHeightScale;
    half fHeightBias;
    half fSelfShadowStrength;

    half2 vDetailBumpTilling; // detail diffuse_bump mapping tilling
    half2 vDetailBlendAmount; // detail diffuse and gloss blend scale
    half fDetailBumpScale; 	  // detail mapping scale

    half blendFac;          // per-pixel layer blending factor

    // shared fields
    int nQuality;           // shader quality level

    half3x3 mTangentToWS;  // tangent to world space transformation matrix - might be required for some vectors
    half3 vView;           // eye vector, fFogFrac
    half3 vNormal;         // normal vector
    half3 vNormalDiffuse;  // diffuse normal vector
    half3 vReflVec;        // reflection vector

    half3 cBumpMap;        // tangent space normal map
    half4 cDiffuseMap;     // diffuse map
    half4 cSpecularMap;    // specular map
    half3 cEnvironment;    // environment map
    half4 cShadowOcclMap;  // shadow map

    half fNdotE;           // per pass constant NdotE
    half fGloss;           // gloss/roughness
    half fAlpha;           // opacity   
    half fAlphaTestRef;    // instanced alpha test value

    // Deferred rendering RTs (multisampling friendly - check frag_get_deferred_buffers in fraglib.cfi for example usage in your custom shader)
    half4 cNormalMapRT;
    half4 cDiffuseAccRT;
    half4 cSpecularAccRT;
    half fSceneDepthRT;

    // Shading accumulation
    half3 cAmbientAcc;
    half3 cDiffuseAcc;
    half3 cBackDiffuseAcc;
    half3 cSpecularAcc;

    // Custom per pass data   
    fragPassCustom pCustom;
};
  
struct fragLightPass
{
    int nType;         // light type
    half3 cDiffuse;    // light diffuse color
    half3 cSpecular;   // light specular color
    half3 cFilter;     // light filter color
    half3 vLight;      // light vector
    half3 vLightWS;    // light position

    half fNdotL;       // normal dot light
    half fFallOff;     // light attenuation  
    half fOcclShadow;  // light shadow term

    half3 cOut;        // light final contribution  

    // ... Custom per light data ...
    fragLightPassCustom pCustom;
}; 


//////////////////////////////// Common shading utilities ////////////////

// assumes 0 is min
half smoothstep_opt(in half maxi, in half x)
{
  x = saturate( x / maxi );
  return  x * x  * (3.0 - 2.0 * x);
}

half GlossToSpecExp255(in half gloss)
{
	return gloss * 255.h;
}

half GetFresnel(half NdotI, half bias, half power)
{
  half facing = (1.0 - NdotI);
  return saturate(bias + (1-bias)*pow(facing, power));
}

half3 GetEnvmapFresnel(half3 specCol0, half gloss, half fNdotE)
{
	const half3 specCol90 = half3( 1, 1, 1 );

	// Empirical approximation to the reduced gain at grazing angles for rough materials
	return lerp( specCol0, specCol90, pow( 1 - saturate( fNdotE ), 5 ) / (40 - 39 * gloss) );
}

half3 GetEnvBRDFFresnel(half3 specCol0, half gloss, half fNdotV, in sampler2D sampEnvBRDF)
{
	// Use a LUT that contains the numerically integrated BRDF for given N.V and smoothness parameters
	// x: integral for base reflectance 0.0, y: integral for base reflectance 1.0
	
	half2 envBRDF = tex2Dlod( sampEnvBRDF, float4( fNdotV, gloss, 0, 0 ) ).xy;
	return lerp( envBRDF.xxx, envBRDF.yyy, specCol0 );
}

half GetAttenuation(half3 L, half fInvRadius, bool bUserFalloff = false, half fFalloffMax = 1.0h)
{
  half3 vDist = L * fInvRadius;
  half fFallOff = saturate(1 + dot(vDist, -vDist));

	if( bUserFalloff )
		fFallOff = smoothstep_opt( fFalloffMax, fFallOff);

  return fFallOff;
}

half GetPhysicalLightAttenuation(half fDist, half fInvRadius, half fAttenuationBulbSize)
{
	const half radius = 1 / fInvRadius;
	half d = fDist;

	// Fadeout last 20% of radius
	half fadeoutFactor = saturate((radius - d) * (fInvRadius / 0.2h));

	// Light attenuation model: 1 / (1 + d/lightsize)^2
	d = max(d - fAttenuationBulbSize, 0);
	half denom = 1 + d / fAttenuationBulbSize;
	half fAttenuation = fadeoutFactor * fadeoutFactor / (denom * denom);

	return fAttenuation;
}

half GetSpotAttenuation(half fPdotL, half fCosAngle, half fRadius)
{
	// Compute cosine of spot direction and light.
	half fSpotFalloff = fCosAngle / (fPdotL+1e-6); // 1 alu
	
	// Apply planar falloff and computed spot falloff.
	half fFallOff = 1.0h - pow(saturate(fSpotFalloff), fRadius); //  4 alu

	return fFallOff;
}

float3 MapCubeToSphere(float3 pos)
{
	float3 pos2 = pos.xyz * pos.xyz;
	return pos * sqrt(1 - 0.5 * pos2.yzx - 0.5 * pos2.zxy + 0.333 * pos2.yzx * pos2.zxy);
}

half3 ShiftVector(half3 V, half3 N, half shiftAmount)
{
  return normalize(V + shiftAmount * N);
  // 3 alu, 1 mad
}

// optimized shift vector - skips normalization - use only when vector lenght not relevant
half3 ShiftVectorOpt(half3 V, half3 N, half shiftAmount)
{
  return (V + shiftAmount * N);
  // 1 mad
}

float3 ToSRGB( float3 col )
{
	return (col.xyz < 0.0031308) ? 12.92 * col.xyz : 1.055 * pow( col.xyz, 1.0 / 2.4 ) - float3( 0.055, 0.055, 0.055 );
}
#if !ORBIS
half3 ToSRGB( half3 col )
{
	return (col.xyz < 0.0031308) ? 12.92h * col.xyz : 1.055h * pow(col.xyz, 1.0h / 2.4h) - half3(0.055h, 0.055h, 0.055h);
}
#endif
//////////////////////////////// Common HDR encoding/decoding ////////////////////////////////

#define MAX_FLOAT						128.h

#define fHDR_EXP_BASE_1_04	1.04h
#define fHDR_EXP_BASE_1_06	1.06h
#define fHDR_EXP_OFFSET			128.h

// Using RGBK format (multiplier in alpha - filtering should work fine)
// quality: good	
half4 EncodeRGBK(in half4 Color, const half fMultiplier, bool bUsePPP = false)
{
	const half4 cScale = half4(half3(1.h, 1.h, 1.h) / fMultiplier, 1.h / 255.0);
	half fMax = saturate(dot(half4(Color.rgb, 1.h), cScale));   // 1 alu

	Color.a = ceil(fMax * 255.h) / 255.h;                       // 3 alu

	Color.xyz /= Color.a * fMultiplier;                         // 2alu

  if( bUsePPP )
  {
	//Color *= rsqrt( Color ); // for best quality

	Color.a = sqrt( Color.a ); // encode just multiplier for performance reasons
  }

  return Color;
}

void EncodeRGBKPair(inout half4 Color0, inout half4 Color1, const half fMultiplier, bool bUsePPP = false)
{
  half fMax0 = saturate(dot(Color0.rgb, 1.h / fMultiplier));    // 1 alu
  half fMax1 = saturate(dot(Color1.rgb, 1.h / fMultiplier));    // 1 alu

  Color0.a = ceil(fMax0 * 255.h) / 255.h;                       // 3 alu
  Color1.a = ceil(fMax1 * 255.h) / 255.h;                       // 3 alu

  Color0.xyz /= Color0.a * fMultiplier;                         // 2alu
  Color1.xyz /= Color1.a * fMultiplier;                         // 2alu
  
  if( bUsePPP )
  {
	  //Color0 *= rsqrt( Color0 ); // for best quality
	  //Color0 *= rsqrt( Color0 ); 

		Color0.a = sqrt( Color0.a ); // encode just multiplier for performance reasons
		Color1.a = sqrt( Color1.a );

  }
}

half4 DecodeRGBK(in half4 Color, const half fMultiplier, bool bUsePPP= false)
{
  if( bUsePPP )
  {
	 //Color.rgb *= Color.rgb * (Color.a * Color.a) * fMultiplier;

	Color.rgb *= (Color.a * Color.a) * fMultiplier;
  }
  else
    Color.rgb *= Color.a * fMultiplier;

  return Color;
}

//////////////////////////////////////////////////////////////////////////////////////////////////
// These functions are used for each and every manipulation with compressed HDR buffer 

#define SCENE_HDR_MULTIPLIER 32.h

half4 EncodeHDRBuffer( in half4 color )
{
	return color;
}

void EncodeLightBufferPair( inout half4 diffuse, inout half4 specular )
{
}

half4 DecodeHDRBuffer( in half4 rgbk )
{
	return rgbk;
}

half4 EncodeLightBuffer( in half4 color )
{
	return color;
}

half4 Decode7E3F(in half4 color)
{
	// Reference	
	//vColor.rgb *= 8.0f;  // Shift performed in resolve and tex bias
	//float3 e = floor( vColor.rgb );
	//float3 m = frac( vColor.rgb );
	//vColor.rgb  = (e == 0.0f) ? 2*m/8 : (1+m)/8 * pow(2,e);  

	float3 me = color.xyz;
	float3 e  = floor(me);
	float3 m  = frac(me);	
		
	color.xyz = (e == 0.0f) ? 2.0f * m : (1.0f+m) * exp2(e);
	color.xyz *= 0.125f;

	return color;
}

half4 DecodeLightBuffer( in half4 color , bool bRangeAdaptHDR = false)
{
	return color;
}

//////////////////////////////// Common Brdfs ////////////////////////////////

half SmoothnessToRoughness(half smoothness)
{
	return (1.0f - smoothness) * (1.0f - smoothness);
}

half RoughnessToSmoothness(half roughness)
{
	return 1.0f - sqrt(roughness);
}

//////////////////////////////// Phong model /////////////////////////////////////
// - Phong model has good properties for plastic and some metallic surfaces. 
// - Good for general use. Very cheap.

#define ONE_OVER_PI 0.31831h
#define ONE_OVER_TWO_PI 0.159155h

// Optimized phong, use if mirrowed reflection vector pre-computed
half Phong(half3 R, half3 L, half Exp)
{	
	half fNormFactor = Exp * ONE_OVER_TWO_PI + ONE_OVER_TWO_PI;		// 1 ALU
  return fNormFactor *  pow(saturate(dot(L, R)), Exp);					// 4 ALU
	// 5 ALU
}

half Phong(half3 N, half3 V, half3 L, half Exp)
{
  half3 R = reflect(-V, N);	// 3 ALU
  return Phong(R, L, Exp);	// 5 ALU
  // 8 ALU
}

//////////////////////////////// Blinn BRDF model /////////////////////////////////////
// - Blinn model has good properties for plastic and some metallic surfaces. 
// - Good for general use. Very cheap.
// *NOTE* We should also multiply by the clamped N.L factor. However this is 
// delegated to the shader part for performance reasons

half BlinnBRDF(half3 N, half3 V, half3 L, half Gloss)
{
  half3 H = normalize(V + L);
	
	// Compute perceptually linear exponent in range 2-2048
	half power = exp2( 10.h * Gloss + 1.h );
	
	half fNormFactor = power * (1.0/8.0) + (2.0/8.0);
	return fNormFactor * pow( saturate( dot( N, H ) ), power );
}

half3 SpecularBRDF(half3 N, half3 V, half3 L, half m, half3 f0, half NormalizationFactor)
{
	half epsilon = 1e-5h;   // epsilon to prevent division by 0
	half m2 = m * m;
	half3 H = normalize( V + L );

	// GGX NDF
	half NdotH = saturate( dot( N, H ) );
	half spec = (NdotH * m2 - NdotH) * NdotH + 1;
	spec = m2 / max((spec * spec) * NormalizationFactor, epsilon);
	
	// Correlated Smith Visibility Term (including Cook-Torrance denominator)
	half NdotL = saturate( dot( N, L ) );
	half NdotV = abs( dot( N, V ) ) + epsilon;
	half Gv = NdotL * sqrt( (-NdotV * m2 + NdotV) * NdotV + m2 );
	half Gl = NdotV * sqrt( (-NdotL * m2 + NdotL) * NdotL + m2 );
	spec *= 0.5h / max(Gv + Gl, epsilon);                                            
		
	// Fresnel (Schlick approximation)
	half f90 = saturate( dot( f0, 0.33333h ) / 0.02h );  // Assume micro-occlusion when reflectance is below 2%
	half3 fresnel = lerp( f0, f90, pow( 1 - saturate( dot( L, H ) ), 5 ) );

	return fresnel * spec;
}

half3 SpecularBRDF(half3 N, half3 V, half3 L, half Gloss, half3 SpecCol)
{
	half m = max(SmoothnessToRoughness( Gloss ), 0.001);  // Prevent highlights from getting too tiny without area lights
	return SpecularBRDF(N, V, L, m, SpecCol, 1.0f);
}

////////////////////////////////////////////////////////////////////////////
// Kaplanyan Average Normal -> half vector approximation

float3 GetAverageQuadNormal(int2 PixelPos, float3 N)
{
    // Calculates the average normal for the current2x2pixel quad in the Gbuffer
    // fill pass.  This is done using ddx / ddy instructions on the geometric normal(with no normal maps applied).  
    N -= ddx_fine(N) * (half(PixelPos.x & 1) - 0.5);
    N -= ddy_fine(N) * (half(PixelPos.y & 1) - 0.5);
    return N;
}

////////////////////////////////////////////////////////////////////////////
// Kaplanyan Filterting Rect

float2 GetKaplanyanFilteringRect(half3x3 TangentToWS, int2 PixelPos)
{
    // Shading frame
    float3 T = TangentToWS[0];
    float3 ShFrameN = normalize(TangentToWS[2]);
    float3 ShFrameS = normalize(T - ShFrameN * dot(ShFrameN, T));
    float3 ShFrameT = cross(ShFrameN, ShFrameS);

    // Use average quad normal as a half vector
    float3 hppW = GetAverageQuadNormal(PixelPos, ShFrameN);

    // Compute half vector in parallel plane
    hppW /= dot(ShFrameN, hppW);
    float2 hpp = float2(dot(hppW, ShFrameS), dot(hppW, ShFrameT));

    // Compute filtering rectangle
    float2 filteringRectange = (abs(ddx_fine(hpp)) + abs(ddy_fine(hpp))) * 0.5;

    // For grazing angles where the first order footprint goes to very high values
    half epsilon = 1e-5h; 
    half roughnessMaxFootprint = RoughnessMaxFootprint + epsilon;
    float2 AgaaKaplanyanRoughnessMaxFootprint = float2(roughnessMaxFootprint, roughnessMaxFootprint);
    filteringRectange = min(AgaaKaplanyanRoughnessMaxFootprint, filteringRectange);
    return filteringRectange;
}

////////////////////////////////////////////////////////////////////////////
// Kaplanyan Roughness

float GetKaplanyanRoughness(half3x3 TangetToWS, int2 PixelPos, float roughness)
{
    float2 filteringRectange = GetKaplanyanFilteringRect(TangetToWS, PixelPos);

    // Covariance matrix of pixel filter's Gaussian (remapped in roughness units)
    // Need x2 because roughness = sqrt(2) * pixel_sigma_hpp
    float2 covarianceMatrix = filteringRectange * filteringRectange * 2.0f * RoughnessBoost;
    
    // Since we have an isotropic roughness to output we conservatively take
    // the largest edge of the filtering rectangle
    float maxIsotropicEdge = max(covarianceMatrix.x, covarianceMatrix.y);

    // Return Beckmann proxy convolution for GGX
    return sqrt(roughness * roughness + maxIsotropicEdge);
}

////////////////////////////////////////////////////////////////////////////
// Anisotropic Kajiya Kay model

half KajiyaKayAnisotropic(half3 T, half3 H, half Exp)
{	
	half TdotH = dot( T, H );
	half fSpec = sqrt( max( 1.0 - TdotH * TdotH, 0.01) );
  
	return pow( fSpec, Exp );
}

////////////////////////////////////////////////////////////////////////////
// Area Light Models

#define AREA_LIGHT_SPHERE		0
#define AREA_LIGHT_RECTANGLE	1

half SphereNormalization( float len, float lightSize, float m )
{
	// Compute the normalization factors.
	// Note: just using sphere normalization (todo: come up with proper disk/plane normalization)
	half dist = saturate(lightSize / len);
	half normFactor = m / saturate( m + 0.5 * dist );
	return normFactor * normFactor;
}

half3 SphereLight(half3 R, half3 L, half m, half4x4 mAreaLightMatr)
{	
	// Intersect the sphere.
	half3 centerDir = L - dot(L, R) * R;
	L = L - centerDir * saturate( mAreaLightMatr[3].y / (length(centerDir)+1e-6) );			
	return L.xyz;
}

half3 RectangleLight(half3 R, half3 L, half m, half4x4 mAreaLightMatr)
{
	// Intersect the plane.
	half RdotN = dot(mAreaLightMatr[0].xyz, R.xyz)+1e-6;
	half intersectLen = dot(mAreaLightMatr[0].xyz, L) / RdotN;
	half3 I = R.xyz * intersectLen - L.xyz;

	// Project the intersection to 2D and clamp it to the light radius to get a point inside or on the edge of the light.
	half2 lightPos2D = half2( dot(I.xyz, mAreaLightMatr[1].xyz), dot(I.xyz, mAreaLightMatr[2].xyz) );
	half2 lightClamp2D = clamp(lightPos2D, -mAreaLightMatr[3].xy, mAreaLightMatr[3].xy);
	
	// New light direction.
	L = L + (mAreaLightMatr[1].xyz * lightClamp2D.x) + mAreaLightMatr[2].xyz * lightClamp2D.y;
	return L.xyz;
}

half4 AreaLightIntersection( half3 N, half3 V, half3 L, half m, half4x4 areaLightMatrix, int lightType )
{
	half4 lightVec = half4(L.xyz, 1.0f);
	half3 R = reflect(V, N);

	[branch] if( lightType == AREA_LIGHT_RECTANGLE )
		lightVec.xyz = RectangleLight(R, L, m, areaLightMatrix);
	else
		lightVec.xyz = SphereLight(R, L, m, areaLightMatrix);

	// Normalize.
	half len = max(length( lightVec.xyz ),  1e-6);
	lightVec.xyz /= len;

	// Energy normalization
	lightVec.w = SphereNormalization( len, lightType == AREA_LIGHT_RECTANGLE ? length(areaLightMatrix[3].xy) : areaLightMatrix[3].y, m );

	return lightVec;
}

half3 AreaLightGGX(half3 N, half3 V, half3 L, half Gloss, half3 SpecCol, half4x4 areaLightMatrix, int lightType)
{
	half m = max(SmoothnessToRoughness( Gloss ), 0.001);	
	half4 lightVec = AreaLightIntersection( N, V, L, m, areaLightMatrix, lightType );	
	return SpecularBRDF(N, V, lightVec.xyz, m, SpecCol, lightVec.w);
}

// Diffuse BRDFs

half3 ComputeNearestLightOnRectangle(half3 vPosition, half3 vLightPoint, float4x4 mAreaLightMatr)
{
	// Calculate light space plane.
	half3 vLightDir = dot(mAreaLightMatr[0].xyz, vLightPoint.xyz) * mAreaLightMatr[0].xyz - vLightPoint.xyz;

	// Calculate the nearest point.
	half2 vSurfArea = float2(dot(vLightDir.xyz, mAreaLightMatr[1].xyz), dot(vLightDir.xyz, mAreaLightMatr[2].xyz));
	half2 vSurfAreaClamp = clamp(vSurfArea.xy, -mAreaLightMatr[3].xy, mAreaLightMatr[3].xy); // 1 alu
	half3 vNearestPoint = mAreaLightMatr[1].xyz * vSurfAreaClamp.x + (mAreaLightMatr[2].xyz * vSurfAreaClamp.y);

	return vLightPoint.xyz + vNearestPoint.xyz;
}

half OrenNayarBRDF(half3 N, half3 V, half3 L, half Gloss, half NdotL)
{
	half m = SmoothnessToRoughness(Gloss);
	m *= m * m;  // Map GGX to Oren-Nayar roughness (purely empirical remapping)
	
	// Approximation of the full quality Oren-Nayar model
	half s = dot(L, V) - dot(N, L) * dot(N, V);
	half t = s <= 0 ? 1 : max(max(dot(N, L), dot(N, V)), 1e-6);
	half A = 1.0h / (1.0h + (0.5h - 2.0h / (3.0h * PI)) * m);
	half B = m * A;
	
	return NdotL * max(A + B * (s / t), 0);
}

half BurleyBRDF(half3 NdotL, half3 NdotV, half3 VdotH, half roughness)
{
	NdotV = max(NdotV, 0.1);  // Prevent overly dark edges
	
	// Burley BRDF with renormalization to conserve energy
	half energyBias = 0.5 * roughness;
	half energyFactor = lerp(1, 1 / 1.51, roughness);
	half fd90 = energyBias + 2.0 * VdotH * VdotH * roughness;
	half scatterL = lerp(1, fd90, pow(1 - NdotL, 5));
	half scatterV = lerp(1, fd90, pow(1 - NdotV, 5));
	
	return scatterL * scatterV * energyFactor * NdotL;
}

half DiffuseBRDF(half3 N, half3 V, half3 L, half Gloss, half NdotL)
{
	// TODO: Share computations with Specular BRDF
	half m = SmoothnessToRoughness(min(Gloss, 1));
	half VdotH = saturate(dot(V, normalize(V + L)));
	half NdotV = abs(dot(N, V)) + 1e-5h;
	
	// Burley BRDF with renormalization to conserve energy
	return BurleyBRDF(NdotL, NdotV, VdotH, m);
}

half3 ThinTranslucencyBRDF(half3 N, half3 L, half3 transmittanceColor)
{
	half w = lerp(0, 0.5, GetLuminance(transmittanceColor));
	half wn = rcp((1 + w) * (1 + w));
	half NdotL = dot(N, L);
	half transmittance = saturate((-NdotL + w) * wn);
	half diffuse = saturate((NdotL + w) * wn);
	
	return transmittanceColor * transmittance + diffuse;
}


////////////////////////////////////////////////////////////////////////////
// Occlusion

half DeriveSpecularOcclusion(half fNdotV, half aoAmount, half smoothness)
{
	// Derive specular occlusion term form ambient occlusion:
	//   Rough surfaces receive full ambient occlusion
	//   Smooth surfaces get more occlusion at grazing angles and less at normal incidence

#if METAL
    // saturate(pow(fNdotV + aoAmount, smoothness) gets translated with a log instruction in Metal
    // we must insure that the log instruction does not take a negative value as input
    // since this will result in "-/+Inf" which will corrupt the buffer
    float tmp = max(1e-8, fNdotV + aoAmount);
    return saturate(pow(tmp, smoothness) - 1 + aoAmount);
#else
    return saturate(pow(fNdotV + aoAmount, smoothness) - 1 + aoAmount);
#endif
}


//////////////////////////////// Vegetation shading ////////////////

// Common vegetation shading

half3 LeafShadingBack(half3 vEye, half3 vLight, half3 vNormal, half3 cDiffBackK, half backViewDep)
{            
  half EdotL=saturate(dot(vEye.xyz, -vLight.xyz));          
  
  // Tweaked NdotL wrapping - Artists request
  half fLdotNBack=saturate(dot(vNormal.xyz, vLight.xyz)*0.6+0.4);

  half powEdotL = EdotL*EdotL;
  powEdotL *= powEdotL;
    
  half3 vBackShading = saturate(powEdotL*backViewDep + (1.0-backViewDep) * fLdotNBack);    

  return vBackShading * cDiffBackK.xyz;
}   

void LeafShadingFront(half3 vEye, half3 vLight, half3 vNormal, half3 cDifK, half3 cSpecK, inout half3 outDif, inout half3 outSpec, half fGloss)
{                                                                                                                                  
  half fLdotNFront=dot(vNormal.xyz, vLight.xyz);      
  // Compute front diffuse term  
#if %GRASS   
  outDif=max(fLdotNFront, 0.5)*cDifK.xyz; 
#else
  outDif=saturate(fLdotNFront)*cDifK.xyz;
#endif
  // compute specular if necessary 
#if !%GRASS
  outSpec = BlinnBRDF(vNormal, vEye, vLight, fGloss) * saturate(fLdotNFront) * cSpecK.xyz;  
#endif
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// Parallel view opacity falloff (for close to parallel leaf polys)

float ParallelOpacityFalloff(float3 vWorldPos, float3 vNormal, float fCapOpacityFalloff, float fAlphaTest)
{
	half3 inverseViewVec = normalize(vWorldPos.xyz); // we use the abs of the dot on next line, so direction of view vec doesn't matter
	half parallelViewOpacity = abs(dot(inverseViewVec, vNormal));

	// cos(alpha ramp start angle) = 0.05
	// cos(alpha ramp end angle) = 0.3
	const half a = 1.0h / (0.3h - 0.05h);
	const half b = -0.05h / (0.3h - 0.05h);

	half x = parallelViewOpacity;

	x = saturate(x*a + b); // remap alpha ramp range to [0..1]
	//x *= (2.0h - x); // eval 2nd order polynomial

	parallelViewOpacity = max(x, fCapOpacityFalloff);

	return 1.0f + parallelViewOpacity * (fAlphaTest - 1.0f);
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// Layer blending

half GetLayerBlendingValue(in sampler2D blendMapSampler, in float2 uv, in float lod, in half vtxAlpha, in half blendFactor, in half blendFalloff, bool bTerrainLayer = false)
{
	#if !ENABLE_TESSELLATION && !%SILHOUETTE_PARALLAX_OCCLUSION_MAPPING // TODO: find way to compute lod without gradients as they cause pixel artifacts at fin / shell transition
		half4 blendMap = GetTexture2D(blendMapSampler, uv);
	#else
		half4 blendMap = GetTexture2DLod(blendMapSampler, float4(uv, 0, lod));
	#endif

	// Terrain layers are a particular case of blend layer, where blendmap is the heightmap and blending
	// is only valid on transition from full opaque (vtx alpha = 1) to fully transparent (vtx alpha = 0)	
	if( bTerrainLayer )
		blendMap = saturate(saturate(vtxAlpha*2-1) + blendMap.x); // 2 inst

	half blendFac = vtxAlpha * blendMap.r * (1 + blendFactor);
	blendFac = saturate(pow(blendFac, blendFalloff));
	return blendFac;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// Silhouette POM, POM & OBM tex coord gen

float4 ComputeBarycentricCorrespondence(in float3 wsPos, in float3 wsTriPos[3], in float3 wsTriDispl[3]) // WS -> TS
{
	float w = 0.0;
	float stepsize = 0.5;

	float3 p0, p1, p2;
	float3 u, v, n, d;

#if ORBIS // workaround for shader code generation bug
	[unroll]
#endif
	for (int i=0; i<10; ++i)
	{
		p0 = wsTriPos[0] + w * wsTriDispl[0];
		p1 = wsTriPos[1] + w * wsTriDispl[1];
		p2 = wsTriPos[2] + w * wsTriDispl[2];

		u = p1 - p0;
		v = p2 - p0;
		n = cross(u, v);
		d = wsPos - p0;

		const float dist = dot(n, d);
		w += (dist > 0.0) ? stepsize : -stepsize;
		stepsize *= 0.5;
	}

	float oneOver4ASquared = 1.0 / dot(n, n);
	float2 bary_uv = float2(dot(cross(d, v), n), dot(cross(u, d), n)) * oneOver4ASquared;

	return float4(1.0 - dot(bary_uv, float2(1, 1)), bary_uv, w);
}

struct CbcWsRes
{
	float3 wsPos;
	float3 wsNorm;
};

CbcWsRes ComputeBarycentricCorrespondence(in float4 bary, in float3 wsTriPos[3], in float3 wsTriDispl[3]) // TS to WS
{
	const float3 disp = wsTriDispl[0].xyz * bary.x + wsTriDispl[1].xyz * bary.y + wsTriDispl[2].xyz * bary.z;
	const float3 pos = wsTriPos[0].xyz * bary.x + wsTriPos[1].xyz * bary.y + wsTriPos[2].xyz * bary.z + disp * bary.w;

	CbcWsRes res;
	res.wsPos = pos;
	res.wsNorm = normalize(disp);

	return res;
}

struct SilMapRes
{
	float2 uvHitPos;
	float4 baryHitPos;
};

SilMapRes SilhouetteMap(in const float3 wsTriPos[3], in const float3 wsTriDispl[3], in const float4 wsClipPlane[5], in const float3 wsViewDir, in const float3 texGenU, in const float3 texGenV, in float lod, in float numSteps, in float displacement)
{
	const float stepSize = 1.0 / clamp(numSteps, 1.f, 512.f);
	
	const float3 wsStartPos = wsViewDir;
	float3 wsEndPos = wsStartPos;
	{
		float tEnd = 1e8;
		for (int i=0; i<5; i++)
		{
			const float3 o = wsStartPos;
			const float3 d = wsViewDir;
	
			const float denom = dot(wsClipPlane[i].xyz, d);
			//if (denom > 0)
			{
				const float t = (wsClipPlane[i].w - dot(wsClipPlane[i].xyz, o)) / denom;
				if (denom > 0 && t < tEnd)
				{
					wsEndPos.xyz = o + d * t;
					tEnd = t;
				}
			}
		}
	}
	
	const float4 baryStart = ComputeBarycentricCorrespondence(wsStartPos, wsTriPos, wsTriDispl);
	const float4 baryEnd = ComputeBarycentricCorrespondence(wsEndPos, wsTriPos, wsTriDispl);
	
	const float3 uvStart = float3(dot(texGenU, baryStart.xyz), dot(texGenV, baryStart.xyz), baryStart.w);
	const float3 uvEnd = float3(dot(texGenU, baryEnd.xyz), dot(texGenV, baryEnd.xyz), baryEnd.w);
	const float3 uvDeltaStep = (uvEnd - uvStart) * stepSize;
	
	float stepped = 0;
	float4 uv = float4(uvStart, lod);
	
	float height = GetTexture2DLod(heightMapSampler, uv).r;
	
	if (height < uv.z)
	{
		{
			for (; stepped < 1.0; stepped += stepSize)
			{
				[flatten]
				if (height >= uv.z)
					break;
	
				uv.xyz += uvDeltaStep;
	
				height = GetTexture2DLod(heightMapSampler, uv).r;
			}
	
			clip(height - uv.z + 0.001);
		}
	
		{
			float pivot = -0.5;
			float bstep = 0.5;
	
			for (int i=0; i<10; i++)
			{
				const float3 lookup = uv.xyz + pivot * uvDeltaStep;
				bstep *= 0.5;
				
				height = GetTexture2DLod(heightMapSampler, float4(lookup, uv.w)).r;

				pivot += (height >= lookup.z) ? -bstep : bstep;
			}
	
			uv.xyz += uvDeltaStep * pivot;
			stepped += stepSize * pivot;
		}
	}
	
	SilMapRes res;
	res.uvHitPos = uv.xy;
	res.baryHitPos = baryStart + (baryEnd - baryStart) * stepped;
	
	return res;
}

#if %BLENDLAYER
float4 ParallaxOcclusionMap(in float2 baseTC, in float2 baseTC2, in float lod, in float3 viewDirNrm, in int numSteps, in float displacement, in float bias, in float blendLayerFactor, in float blendLayer2Tiling)
#else
float4 ParallaxOcclusionMap(in float2 baseTC, in float lod, in float3 viewDirNrm, in int numSteps, in float displacement, in float bias, in float blendLayerFactor, in float blendLayer2Tiling)
#endif
{
    float step =  1.0 / numSteps;
    float bumpScale = displacement;

    float2 delta = float2(viewDirNrm.x, viewDirNrm.y) * bumpScale / (-viewDirNrm.z * numSteps); // / max(-viewDirNrm.z * numSteps, 0.1)

    baseTC -= (1.0 - bias) * numSteps * delta;

    #if %BLENDLAYER
        baseTC2 -= (1.0 - bias) * numSteps * delta;
    #endif

    float NB0 = GetTexture2D(heightMapSampler, baseTC).r;
#if %BLENDLAYER
    float NB02 = GetTexture2D(HeightMap2Sampler, baseTC2.xy * blendLayer2Tiling).r;
    NB0 += blendLayerFactor * (NB02 - NB0);
#endif

    float height = 1 - step;
    float4 offset = float4(baseTC + delta, 0, lod);
    #if %BLENDLAYER
        float4 offset2 = float4(baseTC2 + delta, 0, lod);
    #endif

    float NB1 = GetTexture2D(heightMapSampler, offset).r;
#if %BLENDLAYER
    float NB12 = GetTexture2D(HeightMap2Sampler, offset2.xy * blendLayer2Tiling).r;
    NB1 += blendLayerFactor * (NB12 - NB1);
#endif

    for (int i=0; i<numSteps; i++)
    {
        [flatten]
        if (NB1 >= height)
            break;

        NB0 = NB1;

        height -= step;
        offset.xy += delta;
    #if %BLENDLAYER
        offset2.xy += delta;
    #endif

        NB1 = GetTexture2DLod(heightMapSampler, offset).r;
#if %BLENDLAYER
    NB12 = GetTexture2DLod(HeightMap2Sampler, float4(offset2.xy * blendLayer2Tiling, offset2.zw)).r;
    
    NB1 += blendLayerFactor * (NB12 - NB1);
#endif
    }

    float4 offsetBest = offset;
    #if %BLENDLAYER
        float4 offsetBest2 = offset2;
    #endif
    float error = 1.0;

    float t1 = height;
    float t0 = t1 + step;

    float delta1 = t1 - NB1;
    float delta0 = t0 - NB0;

        float4 intersect = float4(delta * numSteps, delta * numSteps + baseTC);
    #if %BLENDLAYER
        float4 intersect2 = float4(delta * numSteps, delta * numSteps + baseTC2);
    #endif

    float t = 0;

    for (int i=0; i<10; i++)
    {
        [flatten]
        if (abs(error) <= 0.01)
            break;

        float denom = delta1 - delta0;
        t = (t0 * delta1 - t1 * delta0) / denom;
        offsetBest.xy = -t * intersect.xy + intersect.zw;
    #if %BLENDLAYER
        offsetBest2.xy = -t * intersect2.xy + intersect2.zw;
    #endif
        
        float NB = GetTexture2DLod(heightMapSampler, offsetBest).r;
    #if %BLENDLAYER
        float NB2 = GetTexture2DLod(HeightMap2Sampler, float4(offsetBest2.xy * blendLayer2Tiling, offsetBest2.zw)).r;
        NB += blendLayerFactor * (NB2 - NB);
    #endif

        error = t - NB;
        if (error < 0)
        {
            delta1 = error;
            t1 = t;
        }
        else
        {
            delta0 = error;
            t0 = t;
        }
    }

#if %BLENDLAYER
    return float4(offsetBest.xy, offsetBest2.xy);
#else
    return float4(offsetBest.xy, 0.0f, 0.0f);
#endif
}

#if %BLENDLAYER
float4 OffsetMap(in float2 baseTC, float2 baseTC2, in half3 viewDirNrm, in int numSteps, in half displacement, in half bias, in half blendLayerFactor, in float blendLayer2Tiling)
#else
float4 OffsetMap(in float2 baseTC, in half3 viewDirNrm, in int numSteps, in half displacement, in half bias, in half blendLayerFactor, in float blendLayer2Tiling)
#endif
{
    half offset = -bias * displacement;
    float3 newCoords = float3(baseTC, 0);
#if %BLENDLAYER
    float3 newCoords2 = float3(baseTC2, 0);
#endif
    for (int i=0; i<numSteps; ++i)
    {
        half nz = GetNormalMap(normalMapSampler, newCoords.xy).z;
        half h = GetTexture2D(heightMapSampler, newCoords.xy).r;

#if %BLENDLAYER
        const float2 blendLayerCoords = newCoords2.xy * blendLayer2Tiling;
        nz += blendLayerFactor * (GetNormalMap(BumpMap2Sampler, blendLayerCoords.xy).z - nz);
        h += blendLayerFactor * (GetTexture2D(HeightMap2Sampler, blendLayerCoords.xy).r - h);
#endif

        half height = h * displacement + offset;
        newCoords += (height - newCoords.z) * nz * viewDirNrm;
#if %BLENDLAYER
        newCoords2 += (height - newCoords2.z) * nz * viewDirNrm;
#endif
    }

#if %BLENDLAYER
    return float4(newCoords.xy, newCoords2.xy);
#else
    return float4(newCoords.xy, 0, 0);
#endif
}

#define MICRO_DETAIL_QUALITY_DEF 0
#define MICRO_DETAIL_QUALITY_OBM 1
#define MICRO_DETAIL_QUALITY_POM 2
#define MICRO_DETAIL_QUALITY_SPM 3

void GetMicroDetailParams(out int mdQuality, out half mdDisplacement, out half mdHeightBias, out half mdSelfShadowStrength)
{
	mdQuality = MICRO_DETAIL_QUALITY_DEF;
	mdDisplacement = 0.0h;
	mdHeightBias = 1.0h;
	mdSelfShadowStrength = 0.0h;

#if %OFFSET_BUMP_MAPPING || %PARALLAX_OCCLUSION_MAPPING || %SILHOUETTE_PARALLAX_OCCLUSION_MAPPING
	int shQuality = GetShaderQuality();
	#if %SILHOUETTE_PARALLAX_OCCLUSION_MAPPING
		//if (shQuality > QUALITY_HIGH) // explicity ensured through ALLOW_SILHOUETTE_POM flag
		{
			mdQuality = MICRO_DETAIL_QUALITY_SPM;
			mdDisplacement = SilPomDisplacement;
			mdHeightBias = HeightBias;
			mdSelfShadowStrength = SelfShadowStrength;
			return;
		}
	#endif

	#if %OFFSET_BUMP_MAPPING && %PARALLAX_OCCLUSION_MAPPING
		if (shQuality > QUALITY_MEDIUM)
		{
			mdQuality = MICRO_DETAIL_QUALITY_POM;
			mdDisplacement = PomDisplacement;
		}
		else if (shQuality == QUALITY_MEDIUM)
		{
			mdQuality = MICRO_DETAIL_QUALITY_OBM;
			mdDisplacement = ObmDisplacement;
		}
	#elif %PARALLAX_OCCLUSION_MAPPING
		if (shQuality > QUALITY_MEDIUM)
		{
			mdQuality = MICRO_DETAIL_QUALITY_POM;
			mdDisplacement = PomDisplacement;
		}
	#elif %OFFSET_BUMP_MAPPING
		if (shQuality > QUALITY_LOW)
		{
			mdQuality = MICRO_DETAIL_QUALITY_OBM;
			mdDisplacement = ObmDisplacement;
		}
	#endif

	mdHeightBias = HeightBias;
	mdSelfShadowStrength = SelfShadowStrength;
#endif
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// EnvMap Samplers
////////////////////////////////////////////////////////////////////////////////////////////////////

half4 DecodeHDRCubemap(half4 color)
{
	return color;
}

half4 GetEnvironmentCMap(samplerCUBE envMap, in half3 envTC, in half fGloss)
{
	const half numCMapMips = 6.0;  // TODO: Use real cubemap size
	
	half fGlossinessLod = numCMapMips - fGloss * numCMapMips;
  half4 envColor = DecodeHDRCubemap(texCUBElod( envMap, half4(envTC, fGlossinessLod) ));
    
  return envColor;
}

half4 GetEnvironment2DMap(sampler2D envMap, in half2 envTC)
{
  half4 envColor = tex2D(envMap, envTC.xy);

	return envColor;
}

void CubemapBoxParallaxCorrection(inout half3 vReflVec, in half3 vPosition, in half3 vLightPos, in half3 vBoxExtentsMin, in half3 vBoxExtentsMax, inout half fGloss)
{
	// Parallax correction for local cubemaps using a box as geometry proxy

	half3 vReflVecN = normalize(vReflVec.xyz);
		
	// Min/max intersection
	half3 vBoxIntersectionMax = ((vLightPos + vBoxExtentsMax) - vPosition) / vReflVecN;
	half3 vBoxIntersectionMin = ((vLightPos + vBoxExtentsMin) - vPosition) / vReflVecN;
	
	// Intersection test
	half3 vFurthestPlane = vReflVecN > 0.0f ? vBoxIntersectionMax : vBoxIntersectionMin;
	half fDistance = min(min(vFurthestPlane.x, vFurthestPlane.y), vFurthestPlane.z);

	// Apply new reflection position
	half3 vInterectionPos = vPosition + vReflVecN * fDistance;
	vReflVec = vInterectionPos - vLightPos;

	// Modulate glossiness based on reflection vector length.
	//half3 vDist = vBoxPos - vPosition;
	//half fSqrLen = 1.h - saturate(dot(vDist, vDist));
	//fGloss = lerp(fGloss, 1.h, saturate(fGloss * fSqrLen));
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// HDR output

void HDRFogOutput( out pixout OUT, half4 Color, half fDepth, half3 FogColor, half fFogFactor )
{
  Color.xyz = lerp(FogColor.xyz, Color.xyz, fFogFactor);
  OUT.Color = Color;
}

void HDROutput( out pixout OUT, half4 Color, half fDepth)
{
  OUT.Color = Color;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// Depth/Fog output

#include "VolumetricFog.cfi"

// NOTE: float[X] was used in favor of half[X] as precision is curcial and half's is not sufficient!
half4 EncodeSceneDepth( float depth )
{
  return half4(depth,depth,depth,depth);
} 

// This function encodes a depth value so it can be stored in an ARGB8 rendertarget and sets a specific alpha value
float4 EncodeSceneDepthWithAlpha( float depth, half alpha, half alphaTestRef)
{
  float4 ret = EncodeSceneDepth( depth );

	clip(alpha - alphaTestRef);

	ret.a = alpha;

  return ret;
}

// This function encodes a depth value so it can be stored in an ARGB8 rendertarget and sets a specific alpha value
float4 EncodeSceneDepthNoAlpha( float depth)
{
  return EncodeSceneDepth( depth );
}

// This function decodes a depth value coming from an ARGB8 rendertarget/texture 
// NOTE: 1) float[X] was used in favor of half[X] as precision is curcial and half's is not sufficient!
//			 2) smpDepth should be set up as follows...
// 
#ifdef FIXED_POINT
float DecodeSceneDepth( Texture2D <uint> smpDepth, float4 homogeneousPositionTexProj )
{
 	float depthNormalized = GetLinearDepth_ProjTC( smpDepth, homogeneousPositionTexProj );

	// scale back to full range
	return depthNormalized * PS_NearFarClipDist.y;
}
#else
float DecodeSceneDepth( sampler2D smpDepth, float4 homogeneousPositionTexProj )
{
 	float depthNormalized = GetLinearDepth_ProjTC( smpDepth, homogeneousPositionTexProj );

	// scale back to full range
	return depthNormalized * PS_NearFarClipDist.y;
}
#endif

////////////////////////////////////////////////////////////////////////////////////////////////////
// Screen space self-shadowing approximation

half ScreenSpaceSelfShadow(sampler2D smpDepth, float4x4 mViewProjection, float4 tcProj, float3 vPosWS, half3 vLight, half fSoften ) 
{
	// todo: 
	//	- jittering / try out getting away with less samples
	//	- mask samples based on distance, should only self-shadow nearby surface

	half fSign = sign(dot( vLight, miscCamFront ) );

	float3 vLightPos = vPosWS - fSign * vLight.xyz;
	half4 vLightProj = mul( mViewProjection, float4(vLightPos, 1) );
	vLightProj.x = ( vLightProj.x + vLightProj.w)*0.5f / vLightProj.w;
	vLightProj.y = (-vLightProj.y + vLightProj.w)*0.5f / vLightProj.w;		

	vLightProj.xy = vLightProj.xy - tcProj.xy;
	vLightProj.xy *= fSign;

	float2 lightDelta = -vLightProj * PS_ScreenSize.zw*100;
	  
  float h0 = tcProj.w;//GetLinearDepthScaled(smpDepth, tcProj).x;
  float h = h0;

	half hKernelDepthScale = (1 / h0 );
	//lightDelta *= hKernelDepthScale;

  h = min(65535, GetLinearDepthScaled(smpDepth, tcProj + 1.000 * lightDelta).x); 
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.875 * lightDelta).x); 
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.750 * lightDelta).x); //
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.625 * lightDelta).x);
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.500 * lightDelta).x); //
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.375 * lightDelta).x);
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.250 * lightDelta).x); //
  h = min(h, GetLinearDepthScaled(smpDepth, tcProj + 0.125 * lightDelta).x);

	half fSelfShadow = 1 - saturate((h0 - h ) * fSoften);
  return fSelfShadow;
}

////////////////////////////////////////////////////////////////////////////////////////////////////
// Common culling/interpolation functions

float4 BilinearInterp(float2 UV, float4 p0, float4 p1, float4 p2, float4 p3)
{
	float4 bl = float4( (1.f - UV.x) * (1.f - UV.y), UV.x * (1.f - UV.y), (1.f - UV.x) * UV.y, UV.x * UV.y );

	return bl.x * p0 + bl.y * p1 + bl.z * p2+ bl.w * p3;
}

float4 BarycentricInterp(float3 bcs, float4 p0, float4 p1, float4 p2)
{
	return bcs.x * p0 + bcs.y * p1 + bcs.z * p2;
}

float DistanceFromPlane (float3 f3Position, float4 f4PlaneEquation)
{
  return dot(float4( f3Position, 1.0f ), f4PlaneEquation);
}

bool ViewFrustumCull(
                    float3 f3EdgePosition0,         // World space position of patch control point 0
                    float3 f3EdgePosition1,         // World space position of patch control point 1
                    float3 f3EdgePosition2,         // World space position of patch control point 2
                    float4x4 f4ViewFrustumPlanes,   // 4 plane equations (left, right, top, bottom)
                    float fCullEpsilon              // Epsilon to determine the distance outside the view frustum is still considered inside
                    )
{    
	bool4 f4PlaneTest;
	// Left clip plane
	f4PlaneTest.x = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[0]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[0]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[0]) < fCullEpsilon);
	// Right clip plane
	f4PlaneTest.y = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[1]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[1]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[1]) < fCullEpsilon);
	// Top clip plane
	f4PlaneTest.z = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[2]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[2]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[2]) < fCullEpsilon);
	// Bottom clip plane
	f4PlaneTest.w = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[3]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[3]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[3]) < fCullEpsilon);
	
	// Triangle has to pass all 4 plane tests to be visible
	return !all( f4PlaneTest );
}

bool ViewFrustumCull(
                    float3 f3EdgePosition0,         // World space position of patch control point 0
                    float3 f3EdgePosition1,         // World space position of patch control point 1
                    float3 f3EdgePosition2,         // World space position of patch control point 2
                    float3 f3EdgePosition3,         // World space position of patch control point 3
                    float4x4 f4ViewFrustumPlanes,   // 4 plane equations (left, right, top, bottom)
                    float fCullEpsilon              // Epsilon to determine the distance outside the view frustum is still considered inside
                    )
{    
	bool4 f4PlaneTest;
	// Left clip plane
	f4PlaneTest.x = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[0]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[0]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[0]) < fCullEpsilon)
    || (DistanceFromPlane(f3EdgePosition3, f4ViewFrustumPlanes[0]) < fCullEpsilon);
	// Right clip plane
	f4PlaneTest.y = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[1]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[1]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[1]) < fCullEpsilon)
    || (DistanceFromPlane(f3EdgePosition3, f4ViewFrustumPlanes[1]) < fCullEpsilon);
	// Top clip plane
	f4PlaneTest.z = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[2]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[2]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[2]) < fCullEpsilon)
    || (DistanceFromPlane(f3EdgePosition3, f4ViewFrustumPlanes[2]) < fCullEpsilon);
	// Bottom clip plane
	f4PlaneTest.w = (DistanceFromPlane(f3EdgePosition0, f4ViewFrustumPlanes[3]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition1, f4ViewFrustumPlanes[3]) < fCullEpsilon)
		|| (DistanceFromPlane(f3EdgePosition2, f4ViewFrustumPlanes[3]) < fCullEpsilon)
    || (DistanceFromPlane(f3EdgePosition3, f4ViewFrustumPlanes[3]) < fCullEpsilon);
	
	// Quad has to pass all 4 plane tests to be visible
	return !all( f4PlaneTest );
}